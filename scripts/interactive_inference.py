#!/usr/bin/env python3
"""
äº¤äº’å¼æ¨ç†è„šæœ¬
æ”¯æŒç”¨æˆ·ä¸Šä¼ å›¾ç‰‡å¹¶æé—®
"""

import sys
import os
import argparse
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from src.inference.inference_engine import FoodVLMInference
import yaml

def load_qa_templates():
    """åŠ è½½é—®ç­”æ¨¡æ¿"""
    try:
        with open("configs/qa_templates.yaml", 'r', encoding='utf-8') as f:
            return yaml.safe_load(f)
    except Exception as e:
        print(f"Warning: Could not load QA templates: {e}")
        return {}

def show_question_examples(templates):
    """æ˜¾ç¤ºé—®é¢˜ç¤ºä¾‹"""
    if not templates:
        return
    
    print("\nğŸ“ é—®é¢˜ç¤ºä¾‹:")
    print("="*50)
    
    # è¥å…»é—®é¢˜
    if 'nutrition_questions' in templates:
        print("\nğŸ¥— è¥å…»ç›¸å…³é—®é¢˜:")
        for category, questions in templates['nutrition_questions'].items():
            print(f"  {category}:")
            for q in questions[:2]:  # æ˜¾ç¤ºå‰2ä¸ªé—®é¢˜
                print(f"    - {q}")
    
    # é£Ÿæé—®é¢˜
    if 'ingredient_questions' in templates:
        print("\nğŸ¥˜ é£Ÿæç›¸å…³é—®é¢˜:")
        for category, questions in templates['ingredient_questions'].items():
            print(f"  {category}:")
            for q in questions[:2]:
                print(f"    - {q}")
    
    # å¥åº·é—®é¢˜
    if 'health_questions' in templates:
        print("\nğŸ’š å¥åº·æŒ‡æ ‡é—®é¢˜:")
        for category, questions in templates['health_questions'].items():
            print(f"  {category}:")
            for q in questions[:2]:
                print(f"    - {q}")
    
    # é€šç”¨é—®é¢˜
    if 'general_questions' in templates:
        print("\nâ“ é€šç”¨é—®é¢˜:")
        for category, questions in templates['general_questions'].items():
            print(f"  {category}:")
            for q in questions[:2]:
                print(f"    - {q}")

def interactive_mode(inference, templates):
    """äº¤äº’å¼æ¨¡å¼"""
    print("\nğŸ¯ äº¤äº’å¼æ¨¡å¼")
    print("="*50)
    print("è¾“å…¥ 'quit' æˆ– 'exit' é€€å‡º")
    print("è¾“å…¥ 'examples' æŸ¥çœ‹é—®é¢˜ç¤ºä¾‹")
    print("è¾“å…¥ 'help' æŸ¥çœ‹å¸®åŠ©")
    
    while True:
        try:
            # è·å–å›¾ç‰‡è·¯å¾„
            image_path = input("\nğŸ“· è¯·è¾“å…¥å›¾ç‰‡è·¯å¾„: ").strip()
            
            if image_path.lower() in ['quit', 'exit']:
                print("ğŸ‘‹ å†è§!")
                break
            
            if image_path.lower() == 'examples':
                show_question_examples(templates)
                continue
            
            if image_path.lower() == 'help':
                print("\nğŸ“– å¸®åŠ©:")
                print("- è¾“å…¥å›¾ç‰‡è·¯å¾„ï¼Œç„¶åè¾“å…¥é—®é¢˜")
                print("- æ”¯æŒçš„é—®é¢˜ç±»å‹ï¼šè¥å…»ã€é£Ÿæã€å¥åº·æŒ‡æ ‡ã€é€šç”¨é—®é¢˜")
                print("- è¾“å…¥ 'examples' æŸ¥çœ‹é—®é¢˜ç¤ºä¾‹")
                print("- è¾“å…¥ 'quit' é€€å‡º")
                continue
            
            # æ£€æŸ¥å›¾ç‰‡æ˜¯å¦å­˜åœ¨
            if not os.path.exists(image_path):
                print(f"âŒ å›¾ç‰‡ä¸å­˜åœ¨: {image_path}")
                continue
            
            # è·å–é—®é¢˜
            question = input("â“ è¯·è¾“å…¥é—®é¢˜ (ç›´æ¥å›è½¦ä½¿ç”¨é»˜è®¤åˆ†æ): ").strip()
            
            if not question:
                question = None
            
            # åˆ†æå›¾ç‰‡
            print(f"\nğŸ” åˆ†æä¸­...")
            result = inference.analyze_food_image(image_path, question)
            
            if result['success']:
                print("\n" + "="*60)
                print("ğŸ“Š åˆ†æç»“æœ:")
                print("="*60)
                print(result['raw_response'])
                
                if result.get('question'):
                    print(f"\nâ“ é—®é¢˜: {result['question']}")
                
                print(f"\nğŸ“ å›¾ç‰‡: {result['image_path']}")
                print(f"ğŸ¤– æ¨¡å‹: {result['model_key']}")
            else:
                print(f"âŒ åˆ†æå¤±è´¥: {result['raw_response']}")
        
        except KeyboardInterrupt:
            print("\n\nğŸ‘‹ å†è§!")
            break
        except Exception as e:
            print(f"âŒ é”™è¯¯: {e}")

def batch_mode(inference, image_dir, question):
    """æ‰¹é‡æ¨¡å¼"""
    print(f"\nğŸ“ æ‰¹é‡åˆ†ææ¨¡å¼")
    print(f"å›¾ç‰‡ç›®å½•: {image_dir}")
    print(f"é—®é¢˜: {question or 'é»˜è®¤åˆ†æ'}")
    
    # è·å–æ‰€æœ‰å›¾ç‰‡æ–‡ä»¶
    image_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff'}
    image_paths = []
    
    for root, dirs, files in os.walk(image_dir):
        for file in files:
            if any(file.lower().endswith(ext) for ext in image_extensions):
                image_paths.append(os.path.join(root, file))
    
    if not image_paths:
        print("âŒ æœªæ‰¾åˆ°å›¾ç‰‡æ–‡ä»¶")
        return
    
    print(f"ğŸ“Š æ‰¾åˆ° {len(image_paths)} å¼ å›¾ç‰‡")
    
    # æ‰¹é‡åˆ†æ
    results = inference.batch_analyze(image_paths, question)
    
    # ä¿å­˜ç»“æœ
    output_path = "interactive_results.json"
    inference.save_results(results, output_path)
    
    # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
    successful = sum(1 for r in results if r['success'])
    print(f"\nâœ… åˆ†æå®Œæˆ: {successful}/{len(results)} æˆåŠŸ")
    print(f"ğŸ“„ ç»“æœå·²ä¿å­˜åˆ°: {output_path}")

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="Interactive Food VLM Inference")
    parser.add_argument("--model", type=str, required=True, help="Model key (e.g., llava_7b, qwen_vl_7b)")
    parser.add_argument("--lora_path", type=str, help="Path to LoRA weights")
    parser.add_argument("--image_path", type=str, help="Path to single image")
    parser.add_argument("--image_dir", type=str, help="Directory containing images")
    parser.add_argument("--question", type=str, help="Question to ask about the image(s)")
    parser.add_argument("--device", type=str, default="auto", help="Device to use (auto/cuda/cpu)")
    parser.add_argument("--mode", choices=["interactive", "single", "batch"], default="interactive", help="è¿è¡Œæ¨¡å¼")
    
    args = parser.parse_args()
    
    print("ğŸ½ï¸  Food VLM Interactive Inference")
    print("="*60)
    
    # åŠ è½½é—®ç­”æ¨¡æ¿
    templates = load_qa_templates()
    
    # åˆ›å»ºæ¨ç†å™¨
    print(f"ğŸ¤– åŠ è½½æ¨¡å‹: {args.model}")
    inference = FoodVLMInference(
        model_key=args.model,
        lora_path=args.lora_path,
        device=args.device
    )
    
    if args.mode == "interactive":
        # äº¤äº’å¼æ¨¡å¼
        show_question_examples(templates)
        interactive_mode(inference, templates)
    
    elif args.mode == "single":
        # å•å¼ å›¾ç‰‡æ¨¡å¼
        if not args.image_path:
            print("âŒ å•å¼ å›¾ç‰‡æ¨¡å¼éœ€è¦ --image_path å‚æ•°")
            return
        
        print(f"ğŸ“· åˆ†æå›¾ç‰‡: {args.image_path}")
        result = inference.analyze_food_image(args.image_path, args.question)
        
        if result['success']:
            print("\n" + "="*60)
            print("ğŸ“Š åˆ†æç»“æœ:")
            print("="*60)
            print(result['raw_response'])
            
            if result.get('question'):
                print(f"\nâ“ é—®é¢˜: {result['question']}")
        else:
            print(f"âŒ åˆ†æå¤±è´¥: {result['raw_response']}")
    
    elif args.mode == "batch":
        # æ‰¹é‡æ¨¡å¼
        if not args.image_dir:
            print("âŒ æ‰¹é‡æ¨¡å¼éœ€è¦ --image_dir å‚æ•°")
            return
        
        batch_mode(inference, args.image_dir, args.question)

if __name__ == "__main__":
    main()
