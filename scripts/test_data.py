#!/usr/bin/env python3
"""
æ•°æ®æµ‹è¯•è„šæœ¬
ç”¨äºéªŒè¯æ•°æ®é›†åŠ è½½å’Œé¢„å¤„ç†æ˜¯å¦æ­£å¸¸å·¥ä½œ
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from src.data.dataset import FoodDataLoader
from src.models.model_factory import VLMModelFactory

def test_data_loading():
    """æµ‹è¯•æ•°æ®åŠ è½½"""
    print("ğŸ” Testing data loading...")
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists("cal_meta.json"):
        print("âŒ cal_meta.json not found")
        return False
    
    # åŠ è½½æ•°æ®
    try:
        import json
        with open("cal_meta.json", 'r', encoding='utf-8') as f:
            data = json.load(f)
        print(f"âœ… Successfully loaded {len(data)} items")
    except Exception as e:
        print(f"âŒ Error loading data: {e}")
        return False
    
    # æ£€æŸ¥æ•°æ®ç»“æ„
    sample_key = list(data.keys())[0]
    sample_item = data[sample_key]
    
    required_fields = ['title', 'ingredients', 'image_paths', 'partition']
    for field in required_fields:
        if field not in sample_item:
            print(f"âŒ Missing required field: {field}")
            return False
        print(f"âœ… Found field: {field}")
    
    # ç»Ÿè®¡åˆ†å‰²
    partitions = {}
    for item in data.values():
        partition = item.get('partition', 'unknown')
        partitions[partition] = partitions.get(partition, 0) + 1
    
    print(f"\nğŸ“Š Data distribution:")
    for partition, count in partitions.items():
        print(f"  {partition}: {count} items")
    
    return True

def test_image_paths():
    """æµ‹è¯•å›¾ç‰‡è·¯å¾„"""
    print("\nğŸ–¼ï¸  Testing image paths...")
    
    import json
    with open("cal_meta.json", 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    # éšæœºé€‰æ‹©å‡ ä¸ªæ ·æœ¬æµ‹è¯•å›¾ç‰‡è·¯å¾„
    import random
    sample_keys = random.sample(list(data.keys()), min(10, len(data)))
    
    total_images = 0
    valid_images = 0
    
    for key in sample_keys:
        item = data[key]
        image_paths = item.get('image_paths', [])
        
        for img_path in image_paths:
            total_images += 1
            full_path = os.path.join("cal_data", img_path)
            
            if os.path.exists(full_path):
                valid_images += 1
            else:
                print(f"âš ï¸  Missing image: {full_path}")
    
    print(f"ğŸ“ˆ Image validation results:")
    print(f"  Total images checked: {total_images}")
    print(f"  Valid images: {valid_images}")
    print(f"  Success rate: {valid_images/total_images*100:.1f}%")
    
    if valid_images / total_images < 0.8:
        print("âš ï¸  Low image success rate, check cal_data directory")
        return False
    
    return True

def test_model_factory():
    """æµ‹è¯•æ¨¡å‹å·¥å‚"""
    print("\nğŸ­ Testing model factory...")
    
    try:
        factory = VLMModelFactory()
        print("âœ… Model factory created successfully")
        
        # æµ‹è¯•è·å–å¯ç”¨æ¨¡å‹
        models = factory.get_available_models()
        print(f"âœ… Found {len(models)} available models")
        
        # æµ‹è¯•ç³»ç»Ÿè¦æ±‚æ£€æŸ¥
        for model_key in list(models.keys())[:3]:  # æµ‹è¯•å‰3ä¸ªæ¨¡å‹
            compatible, message = factory.check_system_requirements(model_key)
            print(f"  {model_key}: {compatible} - {message}")
        
        return True
        
    except Exception as e:
        print(f"âŒ Model factory test failed: {e}")
        return False

def test_data_processor():
    """æµ‹è¯•æ•°æ®å¤„ç†å™¨"""
    print("\nâš™ï¸  Testing data processor...")
    
    try:
        from transformers import AutoTokenizer, AutoProcessor
        
        # æµ‹è¯•LLaVAæ¨¡å‹
        model_id = "liuhaotian/llava-v1.5-7b"
        print(f"Testing with {model_id}...")
        
        tokenizer = AutoTokenizer.from_pretrained(model_id)
        processor = AutoProcessor.from_pretrained(model_id)
        
        # åˆ›å»ºæ•°æ®åŠ è½½å™¨
        train_loader, val_loader, test_loader = FoodDataLoader.create_data_loaders(
            data_path="cal_meta.json",
            image_dir="cal_data",
            tokenizer=tokenizer,
            processor=processor,
            batch_size=1,
            model_type="llava"
        )
        
        # æµ‹è¯•ä¸€ä¸ªæ‰¹æ¬¡
        for batch in train_loader:
            print(f"âœ… Batch shape:")
            print(f"  Input IDs: {batch['input_ids'].shape}")
            print(f"  Attention Mask: {batch['attention_mask'].shape}")
            print(f"  Pixel Values: {batch['pixel_values'].shape}")
            print(f"  Metadata: {len(batch['metadata'])} items")
            break
            
        return True
        
    except Exception as e:
        print(f"âŒ Data processor test failed: {e}")
        return False

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ§ª Food VLM Data Testing")
    print("="*50)
    
    tests = [
        ("Data Loading", test_data_loading),
        ("Image Paths", test_image_paths),
        ("Model Factory", test_model_factory),
        ("Data Processor", test_data_processor),
    ]
    
    results = []
    
    for test_name, test_func in tests:
        print(f"\n{'='*20} {test_name} {'='*20}")
        try:
            result = test_func()
            results.append((test_name, result))
        except Exception as e:
            print(f"âŒ {test_name} failed with exception: {e}")
            results.append((test_name, False))
    
    # æ€»ç»“
    print("\n" + "="*50)
    print("ğŸ“‹ Test Summary")
    print("="*50)
    
    passed = 0
    for test_name, result in results:
        status = "âœ… PASS" if result else "âŒ FAIL"
        print(f"{test_name}: {status}")
        if result:
            passed += 1
    
    print(f"\nOverall: {passed}/{len(results)} tests passed")
    
    if passed == len(results):
        print("ğŸ‰ All tests passed! Ready for training.")
    else:
        print("âš ï¸  Some tests failed. Please check the issues above.")
    
    return passed == len(results)

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
